{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Project: MovieLens Recommender System\n",
    "Amanda Steigman (as5937), Suman Tripathy (st3275), Romane Goldmuntz (rsg2163)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Business Objectives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the MovieLens dataset, our goal is to build a hybrid recommender system that can recommend a \"Top 10\" movie list for each user. We choose to give the user a larger selection of potential movies to choose from, rather than, for example, showing a \"Top 5,\" in order to improve the chances that at least one of the movies we show will be relevant to the user. It is also common for people to scroll through many movie and show suggestions on platforms like Netflix and Amazon Prime before choosing a certain one.\n",
    "\n",
    "\n",
    "We compare our hybrid approach to two baselines - one in which we simply predict that a user will rate a movie as the average rating the movie has received across all users, and one item-based collaborative filtering recommender. We explore using this item-based recommender in our hybrid system as well.\n",
    "\n",
    "With the user in mind, as mentioned above, for our baseline collaborative filtering algorithm and our first attempt at fitting a hybrid system, we use item-based filtering. The reasons behind that choice are three-fold. First, the number of items is usually much lower than the number of users and new items are added less frequently than new users, which makes the computation time for item-based collaborative filtering much faster than user-based collaborative filtering. The stability of item-based models is also higher than user-based filtering because items will likely overlap more often than users. Finally, we considered interpretability: item-based collaborative filtering enables us to provide the user with an intuitive explanation, such as \"Because you liked movie X, you may enjoy movie Y as well.\"\n",
    "\n",
    "For our hybrid recommender system, we try three different approaches, with all three including the item-based collaborative filtering because of its strong performance. In our model, different types of users are routed through different recommendation algorithms. We define three broad types of users: (1) those who rarely watch movies (i.e. those at or below the 25th percentile for number of movies watched), (2) the typical user who has watched a moderate number of movies (i.e. those between the 25th and 75th percentile), and (3) the frequent movie watcher (i.e. users who have watched at or above the 75th percentile of movies). Our cutoff to be included in the infrequent movie watcher bin is 16, and our threshold to be included in the frequent movie watcher bin is 41.\n",
    "\n",
    "The switching system is a type of parallel ensemble model which allows us to change the algorithm we use based on individuals. In this way, we can also change the way we are recommending movies for a particular user if his \"type\" changes as he watches more movies. \n",
    "\n",
    "In the three hybrid systems we build, we integrate various combinations of Item-Based Collaborative Filtering, Content-Based Recommendation, and Autoencoders. We only use autoencoders to recommend movies to the frequent (type 3) users. Autoencoders, which create latent representations using an encoder-decoder framework, allow us to obtain dense embeddings and are thus useful for making predictions in high-dimensional spaces (i.e. ones where users have watched a large number of movies). In our first and third hybrid system, we use a content-based algorithm to recommend movies to our infrequent users and item-based collaborative filter to recommend movies to our typical users respectively. We are curious to see if this helps relieve the cold start problem for Item-Based Collaborative Filtering, which typically does not perform well on users with few ratings. However, in our second hybrid system, we once again use Collaborative Filtering to recommend movies to both our infrequent and typical users.\n",
    "\n",
    "In the content-based recommender, we include additional information about each movie (explored below) to represent them as high-dimensional vectors. We thought this may be useful if a user has only watched a small number of movies since it doesn't depend on other movies watched and rated, and instead allows us to learn more about the users' preferences in terms of genre, actors, directors, etc. These movie vectors are used to create personalized user profiles for the purpose of making recommendations, which we will leverage Approximate Nearest Neighbors (ANN) to do. Since searching for all of the closest movies in a high-dimensional space is computationally expensive, ANN will help with scaling our recommender system. With ANN, we take a tree-based approach that builds randomized trees partitioned along random dimensions from our data and searches them in parallel to save time. Content-based recommenders are also a good choice of algorithm with the user in mind, since they are easily explainable. For example, additional information about a movie can allow us to tell a user, \"You like comedies with female leads, so we recommend you watch Movie Z.\"\n",
    "\n",
    "We believe the content-based algorithm may also be useful for our typical users since we still have less information available to make recommendations to them than we do for the frequent users, which is why we test it for User Types 1 and 2. Additionally, it is possible that infrequent and typical users are actually quite similar and many of the infrequent users may become typical users over time, so the same approach for recommendations may be useful for both group. However, we also try using the item-based CF for these user groups to account for the possibility that including too much information about too many movies may lead to recommendations that are not generalizable.\n",
    "\n",
    "Since we are working with a huge dataset - around 27 million movie ratings - and because of the inherent sparsity of user-items matrices (i.e. most users do not rate most items) that make recommendations more difficult, we decide to work with a sample of the movie ratings. Because of the dependency between users and items, we cannot randomly sample the dataset. Therefore, we want to include only users who have rated at least a certain number of movies as well as only include movies that have received ratings from at least a certain number of users. We will explore this further in the Sampling section of our report. This will help improve the density of our user-item matrix and make it easier for our recommenders to learn relationships between users and items.\n",
    "\n",
    "As we sample, we choose strategies that follow certain business logic. As mentioned above, we want to ensure as dense a user-item matrix as possible. So, we look at the mean user ratings per movie and the mean number of ratings per user. We sample from the subsets of movies and users, each with above average numbers of ratings respectively. By doing so, we do not only focus on the most popular movies and thus avoid adding bias into our model.\n",
    "\n",
    "We also considered what performance requirements our recommendation system needed to fulfill. We generally assume that users may watch TV / movies after work daily, so we want to pre-compute recommendations offline but we also assume there is no major time crunch. Therefore, we don't worry greatly about space or time constraints, and we simply build these models as offline computations that should simply appear when a user is searching for a movie.\n",
    "\n",
    "Before we begin, we import all necessary packages and start a Spark session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "8diZJDoriTOz"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.recommendation import ALS, ALSModel\n",
    "from pyspark.sql import Row\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder, TrainValidationSplit, CrossValidatorModel\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.types import StringType,IntegerType,DoubleType\n",
    "from pyspark.sql.functions import col, countDistinct\n",
    "from pyspark.sql import functions\n",
    "from collections import defaultdict\n",
    "from surprise.prediction_algorithms import KNNWithMeans\n",
    "from surprise.model_selection import cross_validate\n",
    "from surprise import accuracy\n",
    "import pickle\n",
    "import random\n",
    "import time\n",
    "import seaborn\n",
    "from surprise import Reader, Dataset\n",
    "from IPython.display import HTML, display\n",
    "import tabulate\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName(\"PersProj\").getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Explore the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we look at the total number of users and movies included in the ratings dataset by MovieLens. Since each row is a user-movie rating pair, every user included must have rated at least one movie and every movie included must have been rated by at least one user. We see below that there are 283,228 unique users who have rated at least one movie and 53,889 movies that have at least one rating. For our purposes, we only need to include at least 20,000 users and 1,000 movies. Therefore we sample the data based on our business rules as stated above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bSJtYleRibwf",
    "outputId": "52c030fd-e4ce-498b-e3d6-bc7d7dfe805f",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(27753444, 4)\n",
      "Index(['userId', 'movieId', 'rating', 'timestamp'], dtype='object')\n",
      "283228 unique users\n",
      "53889 unique movies\n"
     ]
    }
   ],
   "source": [
    "# Contains users and their respective movie ratings (float, out of 5.0) and timestamp of the rating\n",
    "ratings = pd.read_csv(\"inputs/ratings.csv\")\n",
    "print(ratings.shape)\n",
    "print(ratings.columns)\n",
    "print(len(ratings['userId'].unique()), \"unique users\")\n",
    "print(len(ratings['movieId'].unique()), \"unique movies\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we look at the distribution of ratings by users. Some users really did only rate one movie, and, on the other extreme, the maximum number of movies rated by a user was close to 24,000 (almost half of the movies in our dataset!). The mean number of movies rated was around 100. When we subset our data before sampling, we will use the mean number of movies rated as our minimum threshold for inclusion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min # of ratings: 1\n",
      "Max # of ratings: 23715\n",
      "Avg # of ratings: 97.98976089934611\n"
     ]
    }
   ],
   "source": [
    "# group by users & count their number of ratings\n",
    "ratings_users = ratings.groupby('userId').size()\n",
    "print('Min # of ratings:', min(ratings_users))\n",
    "print('Max # of ratings:', max(ratings_users))\n",
    "print('Avg # of ratings:', float(sum(ratings_users))/len(ratings_users))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Moving forward, for movies, we can see that 1 was the minimum number of ratings received. The maximum number of ratings a movie received was around 98,000, meaning nearly 35% of users rated that movie. On average, a movie received 515 ratings (meaning it was rated by around 0.2% of users). Any movie that received at least this number of ratings (515) can be included in our sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min # of ratings: 1\n",
      "Max # of ratings: 97999\n",
      "Avg # of ratings: 515.0113010076268\n"
     ]
    }
   ],
   "source": [
    "# group by movies & count their number of ratings\n",
    "ratings_movies = ratings.groupby('movieId').size()\n",
    "print('Min # of ratings:', min(ratings_movies))\n",
    "print('Max # of ratings:', max(ratings_movies))\n",
    "print('Avg # of ratings:', float(sum(ratings_movies))/len(ratings_movies))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Obtain sample and get user-items matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first subset the ratings dataset by filtering based on the mean number of movie ratings and then based on the mean number of user ratings. The data is very skewed because there are many movies with very few reviews. Therefore, by subsetting based on the mean, we are picking a less sparse dataset that is also not just the most popular movies. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 191
    },
    "id": "r4D0c5CkJXIV",
    "outputId": "1d0fc4b9-da4f-4808-d678-e29f583b0152"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1113765937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1113767306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1123990453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1113767242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1113765995</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    userId  movieId  rating   timestamp\n",
       "42       4        1     4.0  1113765937\n",
       "43       4        2     4.0  1113767306\n",
       "44       4        5     2.0  1123990453\n",
       "45       4        6     4.5  1113767242\n",
       "46       4       10     4.0  1113765995"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = ratings.groupby('movieId').size()\n",
    "movies_with_many_ratings = list(m[m > m.mean()].index)\n",
    "movies_with_many_ratings = ratings.loc[ratings['movieId'].isin(movies_with_many_ratings)]\n",
    "\n",
    "u = ratings.groupby('userId').size()\n",
    "user_subset = list(u[u > u.mean()].index)\n",
    "user_ratings = movies_with_many_ratings.loc[movies_with_many_ratings['userId'].isin(user_subset)]\n",
    "user_ratings.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From these movies, we then randomly sample lists of 1000 movie IDs and 20000 user IDs from the filtered dataset and use those IDs to get our sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MatSjwzoLYgo",
    "outputId": "9c3b1468-2841-4e27-a584-3146dfd32a6a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1053727, 4)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_movieIds = random.sample(list(user_ratings['movieId'].unique()), 1000)\n",
    "sample_ratings = user_ratings.loc[user_ratings['movieId'].isin(sample_movieIds)]\n",
    "sample_userIds = random.sample(list(sample_ratings['userId'].unique()), 20000)\n",
    "sample_ratings = sample_ratings.loc[sample_ratings['userId'].isin(sample_userIds)]\n",
    "sample_ratings.to_csv(\"sample_ratings.csv\")\n",
    "sample_ratings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique movies 1000\n",
      "Unique users 20000\n"
     ]
    }
   ],
   "source": [
    "print(\"Unique movies\", len(sample_ratings['movieId'].unique()))\n",
    "print(\"Unique users\", len(sample_ratings['userId'].unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we want to see how our sample's density compares to our original sparse data's density. To do this, we must convert the sampled ratings dataset into a user-item matrix. We see that the new density of our user-items matrix is about 5% as compared to our previous density of about 0.2%. This is clearly a significant improvement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 238
    },
    "id": "DKjeThUFi3Tx",
    "outputId": "6d05461f-1e95-4d43-e09e-d077aee4f585"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.268635%\n"
     ]
    }
   ],
   "source": [
    "user_movies = sample_ratings.pivot_table(index = 'userId', columns = 'movieId', values = 'rating')\n",
    "\n",
    "# calculate density\n",
    "nulls = user_movies.isnull().sum().sum()\n",
    "density = (user_movies.shape[0]*user_movies.shape[1]-nulls)/(user_movies.shape[0]*user_movies.shape[1])*100\n",
    "print(str(density)+'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Webscraping additional data\n",
    "\n",
    "Since we are building a content-based recommender system, we needed to get additional data on the movies included in our sample. The MovieLens dataset comes with tags for each movie, and we combined this with named links and category metadata about the movies that we scraped from Wikipedia pages about each movie. The Wikipedia notebook contains the work done to scrape Wikipedia and clean its output, so this step will be skipped here and we simply read in the data table we generated from that Wikipedia notebook. After removing extremely rare and extremely common tags, as neither would be useful for prediction, we had around 2500 content-based tags describing the movies in our sample. These tags include information about genre, themes, release year, awards nominated for, location, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get top tags\n",
    "movie_vecs = pd.read_csv('inputs/movie_tag_wiki_vecs.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_tags = movie_vecs.sum(axis=0).to_frame()\n",
    "movie_tags.columns = ['Frequency']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see below that the tags have a long right tail - there are a small number of tags that appear more than 200 times, but the majority of tags appear between 20 and 60 times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#distribution of tag freqs\n",
    "seaborn.histplot(movie_tags[movie_tags['Frequency']<1500]['Frequency'],bins=100)\n",
    "plt.title('Distribution of Movies Per Tag')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We next look at the number of tags per movie, which also has a right tail, albeit a smaller one. The majority of movies, though, have between 45 and 200 tags associated with them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#count of tags per movie\n",
    "tags_per_movie = movie_vecs.sum(axis=1).to_frame()\n",
    "tags_per_movie.columns = ['Frequency']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "seaborn.histplot(tags_per_movie['Frequency'],bins=100)\n",
    "plt.title('Distribution of Tags Per Movie')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Define metrics\n",
    "Here, we define the three important metrics that we will use to evaluate and improve our models: precision, recall, and novelty.\n",
    "\n",
    "Since we are interested in measuring our success in movie recommendation, we include precision as a metric for evaluating our recommender systems. In other words, we care more about ensuring that we are showing the users a high ratio of movies that they will enjoy as opposed to the specific numerical rating that a user will give a movie. Below, we define precision as the proportion, out of all of the recommended movies we show to a user (Top 10), that the user will find relevant. We define a movie as \"relevant\" if the user has given the movie a rating of at least 3.5. Our precision is improved when we predict a movie that the user also rated as \"relevant.\" By including movies rated 3.5 or above as opposed to just movies rated 5 - which might be a favorite movie for a given user - for precision, we include a broader spectrum of movies and therefore have higher diversity in our predictions.\n",
    "\n",
    "We also focus on recall, a measure of how many good movies we were able to recommend out of all the movies the user enjoyed from the test set. We count how many movies that we recommend are rated >= 3.5 by the user within the training set and we divide that by how many movies are rated >= 3.5 by the user in the training set TOTAL (regardless of whether we recommended them or not).\n",
    "\n",
    "The last and perhaps most interesting metric we focus on is novelty. There is no industry standard as to how to define novelty, so we sifted through literature and chose our own. We define novelty on an individual movie basis and say a movie is \"novel\" if it is not very commonly recommended to people. Therefore, the novelty of movie i is defined as 1 - ( (# users who were recommended movie i) / (all users)). Thus, we calculate novelty per movie. Then, for each user and his recommended movie list, we sum together all movie novelties. Finally, we average all users' overall novelty scores to end up with a single final value for our movie predictions' novelty. A HIGHER novelty metric is better!\n",
    "\n",
    "As a sidenote, we mention that for our Autoencoder model, we looked at Masked Mean Squared Error (MMSE) and Masked Root Mean Squared Error (MRMSE). However, because it was trained on a different sized dataset and because the content-based model does not output exact predicted ratings, we do not compare MMSE or MRMSE across models. To look at these statistics for the Autoencoders, please check the Deep_Learning_Model_Autoencoders.ipynb file. We also use RMSE to tune our item-based CF algorithm and aim to minimize RMSE on the validation set to pick our best model from our gridsearch.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision(predictions_dict,test_ratings):\n",
    "    precisions = list()\n",
    "    for user, pred_list in predictions_dict.items():\n",
    "        TP = 0\n",
    "        FP = 0\n",
    "        for item in pred_list:\n",
    "            temp_df = test_ratings[(test_ratings['userId']==user) & (test_ratings['movieId']==item)]\n",
    "            temp_df = temp_df.reset_index()\n",
    "            if len(temp_df)>0 and temp_df.loc[0,'rating']>= 3.5:\n",
    "                    TP +=1\n",
    "            else:\n",
    "                FP += 1       \n",
    "        precisions.append(float(TP)/(TP+FP))    # return precision for user\n",
    "    return np.mean(precisions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recall(predictions_dict,test_ratings):\n",
    "    recall = list()\n",
    "    for user, pred_list in predictions_dict.items():\n",
    "        TP = 0\n",
    "        P = 0\n",
    "        temp_df = test_ratings[test_ratings['userId']==user]\n",
    "        for row in temp_df.iterrows():\n",
    "            if row[1]['movieId'] in pred_list and row[1]['rating']>= 3.5:\n",
    "                TP += 1\n",
    "            if row[1]['rating']>= 3.5:\n",
    "                P += 1\n",
    "        if not(TP == 0 and P == 0):\n",
    "            recall.append(float(TP)/(P))\n",
    "    return np.mean(recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def novelty(predictions_dict):\n",
    "    movie_rec_counts = defaultdict(int)\n",
    "    for user, pred_list in predictions_dict.items():\n",
    "        for movie in pred_list:\n",
    "            movie_rec_counts[movie] += 1\n",
    "    user_count = len(predictions_dict)\n",
    "    \n",
    "    # calculate each movie's novelty score\n",
    "    for movie, count in movie_rec_counts.items():\n",
    "        movie_rec_counts[movie] = 1 - (float(count)/(user_count)) # 1 - count(users recommended movie)/count(all users) \n",
    "    \n",
    "    # for each list of recommendations per user, sum up all movie novelty scores, then return average over all users\n",
    "    user_novelty_scores = []\n",
    "    for user, pred_list in predictions_dict.items():\n",
    "        user_novelty = 0\n",
    "        for movie in pred_list:\n",
    "            user_novelty += movie_rec_counts[movie]\n",
    "        user_novelty_scores.append(user_novelty)\n",
    "    return np.mean(user_novelty_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Create a baseline model\n",
    "For each movie, we take the average rating across all users and simply use this average as our baseline recommendation rating. We calculate RMSE, precision, and coverage so that we can have those metrics to compare with our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in training, validation, and test data\n",
    "train_ratings = pd.read_csv('inputs/train_sample_ratings.csv', index_col=0)\n",
    "val_ratings = pd.read_csv('inputs/val_sample_ratings.csv', index_col=0)\n",
    "test_ratings = pd.read_csv('inputs/test_sample_ratings.csv', index_col=0)\n",
    "#combine training and validation for baseline model since we are not crossvalidating that\n",
    "train_valid = pd.concat([train_ratings,val_ratings])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get average rating for each movie from train and use it as prediction for test\n",
    "avg_rating = train_valid.groupby(\"movieId\")['rating'].mean().rename(\"prediction\")\n",
    "train_baseline = train_valid.join(avg_rating, on='movieId')\n",
    "test_baseline = test_ratings.join(avg_rating, on='movieId')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get dictionary to use for precision and recall\n",
    "test_baseline_temp = test_baseline.sort_values(['userId','prediction'],ascending=False).groupby('userId').head(10)\n",
    "test_baseline_temp = test_baseline_temp.groupby(['userId'])['movieId'].agg(lambda x: list(x))\n",
    "test_baseline_dict = {}\n",
    "for user, watched_movies in zip(test_baseline_temp.index, test_baseline_temp):\n",
    "    test_baseline_dict[user] = watched_movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_precision = precision(test_baseline_dict, test_baseline)\n",
    "baseline_recall = recall(test_baseline_dict, test_baseline)\n",
    "baseline_novelty = novelty(test_baseline_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline test precision = 0.71\n",
      "Baseline test recall = 0.81\n",
      "Baseline test novelty = 8.23\n"
     ]
    }
   ],
   "source": [
    "print(\"Baseline test precision = \" + str(round(baseline_precision, 2)))\n",
    "print(\"Baseline test recall = \" + str(round(baseline_recall, 2)))\n",
    "print(\"Baseline test novelty = \" + str(round(baseline_novelty, 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above, we see that our baseline model has a precision of .71, a recall of .81, and a novelty score of 8.23. Let us see how these figures change and hopefully improve in the models ahead."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dP6HkmNmSVfB"
   },
   "source": [
    "### 4. Memory-Based Collaborative Filtering: Item-Based Neighborhood Method\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hJCKdIMncS9P",
    "outputId": "0c0211a5-526c-4203-de51-ec591937d856"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(4, 5, 2.0, None),\n",
       " (4, 2797, 1.5, None),\n",
       " (4, 5010, 5.0, None),\n",
       " (4, 34319, 4.5, None),\n",
       " (4, 736, 3.5, None),\n",
       " (4, 39435, 0.5, None),\n",
       " (4, 1370, 4.0, None),\n",
       " (4, 1792, 4.0, None),\n",
       " (4, 36, 3.5, None),\n",
       " (4, 4308, 0.5, None)]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop extra column\n",
    "train_ratings = train_valid[['userId', 'movieId', 'rating']]\n",
    "test_ratings = test_ratings[['userId', 'movieId', 'rating']]\n",
    "\n",
    "# transfer to the right format for suprise package\n",
    "reader = Reader(rating_scale=(min(train_ratings.rating), max(train_ratings.rating)))\n",
    "ratings = Dataset.load_from_df(train_ratings, reader)\n",
    "reader = Reader(rating_scale=(0.5, 5))\n",
    "ratings_test = Dataset.load_from_df(test_ratings, reader)\n",
    "\n",
    "# to visualize (not head() in suprise dataset)\n",
    "raw_ratings = ratings.raw_ratings\n",
    "raw_ratings[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ost6kOUscRXN"
   },
   "source": [
    "#### 4.1 Best Model via Cross-Validation\n",
    "\n",
    "In this section, we implement our item-based collaborative filtering using a neighborhood-based approach. To define a neighborhood of items, we refer to two different hyperparameters: the similarity measure and the number of items within one neighborhood. \n",
    "\n",
    "The similarity measure defines how close two items are to each other. It can be computed in many different ways, but we decided to focus on cosine and pearson similarity, which are defined below. The reason behind this choice is that both pearson and cosine help mitigate the bias towards popular items and, since we removed the least popular movies from our dataset, our recommender system shouldn't recommend niche items, which is one of the drawbacks of these measures.  \n",
    "\n",
    "> ${Cosine}(i, j)$ = $\\frac{\\sum_{k \\in I_u \\cap I_v} r_{uk} r_{vk}}{\\sqrt{\\sum_{k \\in I_u \\cap I_v}r_{uk}^2} \\sqrt{\\sum_{k \\in I_u \\cap I_v}r_{vk}^2}}$\n",
    "\n",
    "\n",
    "\n",
    "> ${Pearson}(i, j)$ = $\\frac{\\sum_{u \\in U_{ij}} (r_{ui} - \\mu_i)(r_{uj}-\\mu_j)}{\\sqrt{\\sum_{k \\in U_{ij}}(r_{ui} - \\mu_i)^2} \\sqrt{\\sum_{k \\in U_{ij}}(r_{uj} - \\mu_j)^2}}$\n",
    "\n",
    "\n",
    "The number of neighbours that we want to explore range between 5 and 50 with a distance of 5. We added 500 to the sample as a sanity check, to ensure that we shouldn't explore a completely different range of values. \n",
    "\n",
    "To define our optimal hyperparameters for our item-based collaborative filtering, we use cross-validation and gridsearch over our training set. The optimal hyperparameters ared selected based on their RMSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "id": "sp5Q-yebcIoH"
   },
   "outputs": [],
   "source": [
    "# Cross-validation\n",
    "def model_cv_item(sim_measure, k_neighb, data):\n",
    "    model_sim = KNNWithMeans(sim_options ={'name': sim_measure, 'user_based':False}, k = k_neighb)\n",
    "    cv_sim = cross_validate(model_sim, data, measures = ['RMSE'], cv=5, verbose=False)\n",
    "\n",
    "    return cv_sim['test_rmse']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "id": "LX1fVDMxdIcQ"
   },
   "outputs": [],
   "source": [
    "# Gridsearch to tune hyperparameters\n",
    "def gridSearch(k_param, sim_param, data):\n",
    "    mean_scores = []\n",
    "\n",
    "    for k in k_param:\n",
    "        mean_scores.append(np.mean(model_cv_item(sim_param, k, data)))\n",
    "  \n",
    "    best_ind = np.argmin(mean_scores)\n",
    "    best_k = k_param[best_ind]\n",
    "    best_rmse = mean_scores[best_ind]\n",
    "\n",
    "    return mean_scores, best_rmse, best_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "id": "UVj9OcXEdJdi",
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n"
     ]
    }
   ],
   "source": [
    "# Cross-validation and hyperparameters-tuning\n",
    "rmse_scores_cos, lowest_rmse_cos, optimal_k_cos = gridSearch(np.concatenate((np.arange(5,55,5), [500])), 'cosine', ratings)\n",
    "rmse_scores_pear, lowest_rmse_pear, optimal_k_pear = gridSearch(np.concatenate((np.arange(5,55,5), [500])), 'pearson', ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 350
    },
    "id": "8KiKZrlHmy-E",
    "outputId": "6e6290c1-0e41-4138-f64d-724139eb240e"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualization of results\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "k_options = np.concatenate((np.arange(5,55,5), [500]))\n",
    "k_labels = [str(i) for i in k_options]\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize = (15, 5))\n",
    "\n",
    "ax[0].plot(rmse_scores_cos)\n",
    "ax[0].set_xticks(np.arange(0,11, 1))\n",
    "ax[0].set_xticklabels(k_labels)\n",
    "ax[0].set_xlabel('k')\n",
    "ax[0].set_ylabel('RMSE')\n",
    "ax[0].set_title('RMSE per k neighbors - cosine similarity')\n",
    "\n",
    "ax[1].plot(rmse_scores_pear)\n",
    "ax[1].set_xticks(np.arange(0,11, 1))\n",
    "ax[1].set_xticklabels(k_labels)\n",
    "ax[1].set_xlabel('k')\n",
    "ax[1].set_ylabel('RMSE')\n",
    "ax[1].set_title('RMSE per k neighbors - pearson similarity')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Smeh_0FEm4YW",
    "outputId": "8c9834c2-6b95-4575-b12a-d72b260f45a7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the optimal similarity measure is pearson similarity with an optimal k of 30\n"
     ]
    }
   ],
   "source": [
    "# Optimal parameters\n",
    "if lowest_rmse_cos < lowest_rmse_pear:\n",
    "    opt_sim = 'cosine'\n",
    "    opt_k = optimal_k_cos\n",
    "    print('the optimal similarity measure is cosine similarity with an optimal k of', opt_k)\n",
    "\n",
    "else:\n",
    "    opt_sim = 'pearson'\n",
    "    opt_k = optimal_k_pear\n",
    "    print('the optimal similarity measure is pearson similarity with an optimal k of', opt_k)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EtvTMPw6pFnL"
   },
   "source": [
    "We can see that we obtain the best RMSE with pearson similarity measure and with a number of neighbors k = 30. We now fit our train set with these hyperparameters and predict the results on our test set, before computing the precision, recall, and novelty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 0.8343\n"
     ]
    }
   ],
   "source": [
    "#Format change for trainset (necessary for surprise)\n",
    "trainset = ratings.build_full_trainset()\n",
    "testset = ratings_test.raw_ratings\n",
    "testset = ratings.construct_testset(testset)\n",
    "\n",
    "opt_model = KNNWithMeans(sim_options ={'name': 'pearson', 'user_based':False}, k = optimal_k_pear)\n",
    "\n",
    "opt_model.fit(trainset)\n",
    "results = opt_model.test(testset)\n",
    "\n",
    "test_result = opt_model.test(testset)\n",
    "test_rmse = accuracy.rmse(test_result)\n",
    "\n",
    "# get dictionary and df to use for precision and recall\n",
    "test_item = pd.DataFrame(test_result).sort_values(['uid','est'],ascending=False).groupby('uid').head(10)\n",
    "test_item = test_item.rename(columns={\"uid\": \"userId\", \"est\": \"rating\", \"iid\": \"movieId\"})\n",
    "test_item_temp = test_item.groupby(['userId'])['movieId'].agg(lambda x: list(x))\n",
    "test_item_dict = {}\n",
    "for user, watched_movies in zip(test_item_temp.index, test_item_temp):\n",
    "    test_item_dict[user] = watched_movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1L6KinYKqA58",
    "outputId": "f8844781-3fd9-493f-e8bc-2c78bf7aa510"
   },
   "outputs": [],
   "source": [
    "cf_precision = precision(test_item_dict, test_item)\n",
    "cf_recall = recall(test_item_dict, test_item)\n",
    "cf_novelty = novelty(test_item_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6y67xFXHr0X5",
    "outputId": "d207d3a8-dd46-41ad-95c3-68836983c0a8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The precision of our best Item-Based CF model is: 0.72\n",
      "The recall of our best Item-Based CF model is: 1.0\n",
      "The novelty of our best Item-Based CF model is: 8.25\n"
     ]
    }
   ],
   "source": [
    "print('The precision of our best Item-Based CF model is:', round(cf_precision,2))\n",
    "print('The recall of our best Item-Based CF model is:', round(cf_recall,2))\n",
    "print('The novelty of our best Item-Based CF model is:',  round(cf_novelty,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save and output recommendations\n",
    "user_recs = {}\n",
    "for user in test_item['userId'].unique():\n",
    "    user_item = test_item[test_item['userId'] == user]\n",
    "    best_movies = list(user_item['movieId'].head(10))\n",
    "    user_recs[user] = best_movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle model - need to get actual predictions\n",
    "file_to_write = open(\"outputs/item_based.pickle\", \"wb\")\n",
    "pickle.dump(user_recs, file_to_write)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Hybrid Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, we built our hybrid models by combining model recommendations from an Item-Based Collaborative Filtering model, an Autoencoder model, and a Content-Based model. For more information on how we built and evaluated the Autoencoder and Content-Based algorithms, please see the Deep_Learning_Model_Autoencoders and Content-based notebooks, respectively.\n",
    "\n",
    "For all three of the hybrid models, we output up to 10 recommended movies per user in a dictionary format with key = userId and value = a list of recommended movies for that user. We then pickled all these dictionaries and stored them in the output/ folder to make the models' recommendations easy to retrieve and combine in the following hybrid models. \n",
    "\n",
    "First, we split the datasets into the quantile user groups as mentioned in our introductory section. We make different data splits for each of our three hybrid models according to their format."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.1 Splitting the datasets for routing into correct hybrid model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting datasets based on quartile for number of movies watched\n",
    "def user_split(data, split_at_quantile_lst):\n",
    "    if len(split_at_quantile_lst) == 1:\n",
    "        distribution = pd.DataFrame(data['userId'].value_counts().rename_axis('userId').reset_index(name = 'counts'))\n",
    "        thresh = distribution.counts.quantile(split_at_quantile_lst[0])\n",
    "        user_ids_below = distribution[distribution.counts <= thresh]\n",
    "        user_ids_below = user_ids_below['userId'].to_list()\n",
    "        user_ids_above = distribution[distribution.counts > thresh]\n",
    "        user_ids_above = user_ids_above['userId'].to_list()\n",
    "        data_below = data[data['userId'].isin(user_ids_below)]\n",
    "        data_above = data[data['userId'].isin(user_ids_above)]\n",
    "        return data_below, data_above\n",
    "    elif len(split_at_quantile_lst) == 2:\n",
    "        distribution = pd.DataFrame(data['userId'].value_counts().rename_axis('userId').reset_index(name = 'counts'))\n",
    "        thresh = distribution.counts.quantile(split_at_quantile_lst[0])\n",
    "        user_ids_low = distribution[distribution.counts <= thresh]\n",
    "        user_ids_low = user_ids_low['userId'].to_list()\n",
    "        thresh2 = distribution.counts.quantile(split_at_quantile_lst[1])\n",
    "        user_ids_middle = distribution[(distribution.counts <= thresh2) & (distribution.counts > thresh)]\n",
    "        user_ids_middle = user_ids_middle['userId'].to_list()\n",
    "        user_ids_high = distribution[distribution.counts > thresh2]\n",
    "        user_ids_high = user_ids_high['userId'].to_list()\n",
    "        data_lowest = data[data['userId'].isin(user_ids_low)]\n",
    "        data_middle = data[data['userId'].isin(user_ids_middle)]\n",
    "        data_high = data[data['userId'].isin(user_ids_high)]\n",
    "        return data_lowest, data_middle, data_high"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are the various formats of the three hybrid models we try.\n",
    "\n",
    "(1) Hybrid Model 1\n",
    "\n",
    "> User group 1 (<25th percentile of movies watched)           ---->     Content-Based Model  <br>\n",
    "> User group 2 (>25th, <75th percentile of movies watched)    ---->     Item-Based Collaborative Filtering <br>\n",
    "> User group 3 (>75th percentile of movies watched)           ---->     Autoencoder   <br>\n",
    "\n",
    "(2) Hybrid Model 2\n",
    "\n",
    "> User group 1 and 2 (<75th percentile of movies watched)     ---->     Item-Based Collaborative Filtering <br>\n",
    "> User group 3 (>75th percentile of movies watched)           ---->     Autoencoder   <br>\n",
    "\n",
    "(3) Hybrid Model 3\n",
    "\n",
    "> User group 1 (<25th percentile of movies watched)           ---->     Content-Based Model  <br>\n",
    "> User group 2 and 3 (>25th percentile of movies watched)     ---->     Item-Based Collaborative Filtering <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model 1 sets\n",
    "content_train1, cf_train1, autoencoder_train1 = user_split(train_ratings, [0.25, 0.75])\n",
    "content_val1, cf_val1, autoencoder_val1 = user_split(val_ratings, [0.25, 0.75])\n",
    "content_test1, cf_test1, autoencoder_test1 = user_split(test_ratings, [0.25, 0.75])\n",
    "\n",
    "#model 2 sets\n",
    "cf_train2, autoencoder_train2 = user_split(train_ratings, [0.75])\n",
    "cf_val2, autoencoder_val2 = user_split(val_ratings, [0.75])\n",
    "cf_test2, autoencoder_test2 = user_split(test_ratings, [0.75])\n",
    "\n",
    "#model 3 sets\n",
    "content_train3, cf_train3 = user_split(train_ratings, [0.25])\n",
    "content_val3, cf_val3 = user_split(val_ratings, [0.25])\n",
    "content_test3, cf_test3 = user_split(test_ratings, [0.25])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we read in the recommendations for each user in our test set. As mentioned above, we pickled the dictionaries with recommended outputs for each user for all trained models for easy access and use in the hybrid model. We get the relevant ratings for each user based on which user group they fall into (based on # movies rated) and essentially concatenate the dictionary recommendations so that we have one dictionary for each of our three hybrid systems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "cf_dict = pickle.load(open( \"outputs/item_based.pickle\", \"rb\"))\n",
    "ae_dict = pickle.load(open(\"outputs/DL_recommendations.pickle\", \"rb\"))\n",
    "content_dict = pickle.load(open(\"outputs/all_content_recommendations.pickle\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create 3 dicts for item-based cf (one for each system)\n",
    "cf_dict1 = {key: value for key, value in cf_dict.items() if key in cf_test1['userId'].unique()}\n",
    "cf_dict2 = {key: value for key, value in cf_dict.items() if key in cf_test2['userId'].unique()}\n",
    "cf_dict3 = {key: value for key, value in cf_dict.items() if key in cf_test3['userId'].unique()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create 2 dicts for content-based (one for system 1 and one for system 3)\n",
    "content_dict1 = {key: value for key, value in content_dict.items() if key in content_test1['userId'].unique()}\n",
    "content_dict3 = {key: value for key, value in content_dict.items() if key in content_test3['userId'].unique()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenate so we have one overall dictionary per system\n",
    "hybrid1_recs = content_dict1.copy()\n",
    "hybrid1_recs.update(cf_dict1)\n",
    "hybrid1_recs.update(ae_dict)\n",
    "\n",
    "hybrid2_recs = cf_dict2.copy()\n",
    "hybrid2_recs.update(ae_dict)\n",
    "\n",
    "hybrid3_recs = content_dict3.copy()\n",
    "hybrid3_recs.update(cf_dict3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.2 Model Evaluation\n",
    "Here, we evaluate each of the three hybrid models to find the best one and use that in the following section as our ultimate recommender system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each system, get precision, recall, and novelty\n",
    "hybrid1_precision = precision(hybrid1_recs, test_ratings)\n",
    "hybrid2_precision = precision(hybrid2_recs, test_ratings)\n",
    "hybrid3_precision = precision(hybrid3_recs, test_ratings)\n",
    "\n",
    "hybrid1_recall = recall(hybrid1_recs, test_ratings)\n",
    "hybrid2_recall = recall(hybrid2_recs, test_ratings)\n",
    "hybrid3_recall = recall(hybrid3_recs, test_ratings)\n",
    "\n",
    "hybrid1_novelty = novelty(hybrid1_recs)\n",
    "hybrid2_novelty = novelty(hybrid2_recs)\n",
    "hybrid3_novelty = novelty(hybrid3_recs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tbody>\n",
       "<tr><td>                                  </td><td>Precision</td><td>Recall</td><td>Novelty</td></tr>\n",
       "<tr><td>Baseline                          </td><td>0.71     </td><td>0.81  </td><td>8.23   </td></tr>\n",
       "<tr><td>Item-Based Collaborative Filtering</td><td>0.72     </td><td>1.0   </td><td>8.25   </td></tr>\n",
       "<tr><td>Hybrid Model 1                    </td><td>0.32     </td><td>0.37  </td><td>8.65   </td></tr>\n",
       "<tr><td>Hybrid Model 2                    </td><td>0.57     </td><td>0.73  </td><td>7.49   </td></tr>\n",
       "<tr><td>Hybrid Model 3                    </td><td>0.47     </td><td>0.46  </td><td>9.39   </td></tr>\n",
       "</tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "table = [[\"\", \"Precision\", \"Recall\", \"Novelty\"],\n",
    "         [\"Baseline\", round(baseline_precision, 2), round(baseline_recall, 2), round(baseline_novelty, 2)],\n",
    "         [\"Item-Based Collaborative Filtering\", round(cf_precision, 2), round(cf_recall, 2), round(cf_novelty, 2)],\n",
    "         [\"Hybrid Model 1\", round(hybrid1_precision, 2), round(hybrid1_recall, 2), round(hybrid1_novelty, 2)],\n",
    "         [\"Hybrid Model 2\", round(hybrid2_precision, 2), round(hybrid2_recall, 2), round(hybrid2_novelty, 2)],\n",
    "         [\"Hybrid Model 3\", round(hybrid3_precision, 2), round(hybrid3_recall, 2), round(hybrid3_novelty, 2)]]\n",
    "display(HTML(tabulate.tabulate(table, tablefmt='html')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pickle the best hybrid model - model 2\n",
    "file_to_write = open(\"outputs/hybrid2_recs.pickle\", \"wb\")\n",
    "pickle.dump(hybrid2_recs, file_to_write)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Recommendations and Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interestingly enough, our best hybrid model in terms of precision and recall is number 2, which uses Item-Based Collaborative Filtering for all users below the 75th percentile of number of movies watched and Autoencoders for users above the 75th percentile. This perhaps implies that the content-based model did not work particularly well and ultimately was unable to solve the cold start problem for CF. Thus, we proceed onwards with hybrid model 2 to make recommendations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, we create a function that returns the names of the Top 10 recommended movies from our second hybrid system for any user of interest. Because we want this function to run completely end to end, we recreate our recommendation dictionary again inside."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_movies(user):\n",
    "    # import movies so we can show titles\n",
    "    movies = pd.read_csv(\"inputs/movies.csv\")\n",
    "    movies_dict = dict(zip(movies.movieId, movies.title))\n",
    "    #load the recommendations\n",
    "    hybrid2_recs = pickle.load(open(\"outputs/hybrid2_recs.pickle\",\"rb\"))\n",
    "    #get movie ids\n",
    "    movie_recs = hybrid2_recs[user]\n",
    "    #look up movie titles and rank them\n",
    "    movie_titles = []\n",
    "    i = 1\n",
    "    for movie in movie_recs:\n",
    "        #clean title\n",
    "        t = movies_dict[movie]\n",
    "        t = str.strip(t)\n",
    "        clean_title = t[:-7]\n",
    "        if('The' in clean_title[-3:]):\n",
    "            clean_title = 'The ' + clean_title[:-5]\n",
    "        if('A' in clean_title[-1:]):\n",
    "            clean_title = 'A ' + clean_title[:-3]\n",
    "        movie_titles.append(str(i) + '. ' + str(clean_title))\n",
    "        i += 1\n",
    "    #output recs for user\n",
    "    print(\"Based on your viewing history, we recommend the following movies for you to try next: \\n \\t\" + '\\n \\t'.join([str(m) for m in movie_titles]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We show recommendations for one user who was routed to the item-based algorithm and one user who was routed to the autoencoder algorithm by randomly selecting one user from each of the corresponding test sets. We take a qualitative look at these recommendations and also show them as a proof of concept."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#commented out in order to maintain the same users\n",
    "#randomly select one user from item-based\n",
    "#cf_test2 = cf_test2.reset_index()\n",
    "#random1 = random.randint(0,len(cf_test2))\n",
    "#user1 = cf_test2.loc[random1,'userId']\n",
    "#randomly select one user from autoencoders\n",
    "#autoencoder_test2 = autoencoder_test2.reset_index()\n",
    "#random2 = random.randint(0,len(autoencoder_test2))\n",
    "#user2 = autoencoder_test2.loc[random2,'userId']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The user we selected from the item-based group is User 26764\n",
      "The user we selected from the autoencoder group is User 113660\n"
     ]
    }
   ],
   "source": [
    "#print(\"The user we selected from the item-based group is User \" + str(user1) + \"\\n\" +\n",
    "#     \"The user we selected from the autoencoder group is User \" + str(user2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we look at User 26764, who has rated 14 movies, placing him in the first quartile and routing him to the item-based algorithm. Our recommendations below are quite cohesive - we can deduce that this user is probably interested in action movies - yet the recommendations still offer a wide range of movies that fit into this genre (i.e. movies from wartime, like Courage Under Fire and The English Patient, are recommended, but so are fantasy movies, like Highlander and Star Wars)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on your viewing history, we recommend the following movies for you to try next: \n",
      " \t1. Wallace & Gromit: The Best of Aardman Animation\n",
      " \t2. Indiana Jones and the Last Crusade\n",
      " \t3. Star Wars: Episode VI - Return of the Jedi\n",
      " \t4. Before Sunrise\n",
      " \t5. The Last of the Mohicans\n",
      " \t6. Highlander\n",
      " \t7. A Time to Kill\n",
      " \t8. Courage Under Fire\n",
      " \t9. The English Patient\n",
      " \t10. Twister\n"
     ]
    }
   ],
   "source": [
    "recommend_movies(26764)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we look at User 113660, a frequent movie watcher (has rated 38 movies total) who we used the autoencoders to recommend movies to. This user also appears to enjoy action movies, and is even recommended 2 of the same movies as is our previous user (Star Wars and Indiana Jones; it is also likely that these two movies were quite popular). However, we can see that the types of action movies are quite different from our previous user and that this user's taste also appears to be more varied (recommendations include Being John Malkovich, a comedy, and two thrillers: Silence of the Lambs and Memento)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on your viewing history, we recommend the following movies for you to try next: \n",
      " \t1. The Silence of the Lambs\n",
      " \t2. The Lord of the Rings: The Fellowship of the Ring\n",
      " \t3. Memento\n",
      " \t4. The Princess Bride\n",
      " \t5. Star Wars: Episode VI - Return of the Jedi\n",
      " \t6. Taxi Driver\n",
      " \t7. Indiana Jones and the Last Crusade\n",
      " \t8. Terminator 2: Judgment Day\n",
      " \t9. Being John Malkovich\n",
      " \t10. Die Hard\n"
     ]
    }
   ],
   "source": [
    "recommend_movies(113660)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall, we see some interesting results from our hybrid model. Two of our hybrid models are able to achieve higher novelty which indicates that perhaps these systems are able to provide more individualized recommendations to the users, even if they are not necessarily movies that the user will like more. However, all of the hybrid models performed worse than both the baseline and the item-based collaborative filtering model in terms of precision and recall. These results are relatively surprising because we had hoped the content-based model could help with collaborative filtering's cold start problem. By incorporating in various sources like MovieLens tag data as well as the abundant Wikipedia data we scraped, we had hoped to create great movie representations. Perhaps, however, the very high number of tags and Wiki terms actually created overly high dimensional movie vectors that could not generalize well. We also thought Autoencoders could be an exciting technique for the most frequent movie watcher group, but these results actually show that sometimes the simplest models are truly good enough (if not the best).\n",
    "\n",
    "We specifically focused on creating hybrid models that addressed user groups differently based on their rating frequency, but it seems that baseline and collaborative filtering handle these user groups better than content-based and deep learning. Future work could involve more intentional user segmentation by examining the CF cold start problem more closely.\n",
    "\n",
    "Another limitation of our model's output is that not all users are actually given 10 recommendations, which would not be very useful for an actual company's solution. This is a potential watchout, but in the future, we could try combining various models' outputs in order to guarantee 10 recommendations per user.\n",
    "\n",
    "Our final recommendation to the manager would simply be to use the item-based recommender system over the hybrid system. While novelty is a nice feature to have, ultimately we believe that the priority for the hiring manager should be to show the user movies that he will watch and enjoy. Therefore, when comparing hybrids on their own, we would recommend hybrid model 2 to the hiring manager, even though it has the lowest novelty of all of our models. However, across all models, our ultimate recommendation is to use the Item-Based Collaborative Filtering system due to its superior performance across all three metrics we measure. \n",
    "\n",
    "Finally, we would encourage the manager to try to experiment with other ensemble techniques. For example, instead of segregating users into groups based on certain criteria, we could instead try aggregating different models' predictions on all users. Additionally, we would recommend that the manager try utilizing user data, such as any demographic data the user provides when signing up to use the service or any other available information, such as search and click history, to try and improve recommendations, specifically for the cold start problem when little to no ratings are available."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Personalization-Hw2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
